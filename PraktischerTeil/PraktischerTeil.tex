\chapter{Prototypische Umsetzung}     

Im folgenden Kapitel wird der Prototyp genauer betrachtet und die verschiedenen Aspekte seiner Entwicklung und Implementierung werden erläutert. Es werden dabei die verwendeten Technologien und die Art der Speicherung und Bereitstellung von Binärdaten beleuchtet. Um die Performance zu bewerten, werden Messungen auf generierte Testdaten durchgeführt. Insgesamt dient das Kapitel als Grundlage für weitere Untersuchungen und die Optimierung des Prototyps.\\                               

\section{Überblick und Vorgehensweise}

Zunächst wird auf die eingesetzten Technologien eingegangen, die bei der Entwicklung des Prototyps verwendet werden. Dies umfasst das Framework Spring Boot und Programmiersprachen, die zur Umsetzung des Prototyps genutzt werden. Ein besonderes Augenmerk wird auf die Speicherung der Binärdaten gelegt. Hier werden verschiedene Ansätze betrachtet, wie beispielsweise die Verwendung von dem AWS SDK und der Google Client Libraries. Des Weiteren wird die Bereitstellung der Binärdaten behandelt. Hier wird die Methode der Signed URLs betrachtet, um die Daten effizient an die Anwender zu übertragen. Um die Leistung des Prototyps zu bewerten, werden Testdaten mit zufälligem Inhalt generiert. Dies ermöglicht eine realistische Simulation der Tickets und Rechnungen in leoticket und erlaubt eine Bewertung der Performance der Cloud Provider. Die Messungen werden auf einem virtuellen Server durchgeführt, um eine isolierte Umgebung zu gewährleisten. Dies ermöglicht es, Performance Messungen unabhängig von anderen Prozessen oder Anwendungen auf dem Host-System durchzuführen, ohne Störungen zu verursachen.\\

\newpage

\section{Eingesetzte Technologien}

Für die Umsetzung des Prototyps werden die folgenden Technologien eingesetzt:

\begin{itemize}
	\item Spring Boot v3
	\item AWS SDK 2.0 Version
	\item GC Storage client library
	\item Java SDK v17
	\item Apache Maven v3.9.1
	\item Maven Schema v4.0.0
	\item AWS Toolkit
	\item aws cli
	\item gcloud cli
\end{itemize}

Für die Implementierung wurde die Entwicklungsumgebung IntelliJ IDEA Ultimate verwendet. IntelliJ bietet ein Plugin namens \verb|AWS Toolkit| an. Als Framework wurde die aktuellste Version von Spring Boot (Version 3) zum Zeitpunkt der Erstellung des Prototyps verwendet. Spring Boot stellt SDKs beider Cloud-Anbieter als Maven-Abhängigkeiten zur Verfügung.

\begin{quote}
	Am 17. März 2021 wurde die neue Version des Spring Cloud AWS 2.3 veröffentlicht. Spring Cloud GCP und Spring Cloud AWS sind nicht mehr Teil des Spring Cloud Releases. Nicht Teil des Releases zu sein bedeutet auch, dass sie aus der Spring Cloud Organisation auf Github herausgenommen worden sind und dadurch neue Maven Package Namen haben. Das neue Package für Spring Cloud AWS heißt nun \glqq io.awspring.cloud\grqq, vgl. \cite{spring-cloud-announce}. 
\end{quote}

Die unten aufgeführten Maven Abhängigkeiten werden für AWS S3 und Cloud Storage verwendet:

\begin{lstlisting}[language=XML]
	<dependency>
        	<groupId>com.google.cloud</groupId>
        	<artifactId>spring-cloud-gcp-starter-storage</artifactId>
    </dependency>
\end{lstlisting}

\begin{lstlisting}[language=XML]
	dependency>
        	<groupId>io.awspring.cloud</groupId>
        	<artifactId>spring-cloud-aws-s3</artifactId>
        	<version>3.0.0</version>
    </dependency>
\end{lstlisting}

Als Spring Cloud GCP Version wird die 4.2.0 verwendet. Beide Spring Cloud Abhängigkeien werden von der Community auf Github verwaltet und aktualisiert. Für die Erstellung des Spring Boot Projekts wurde der Spring Initializier von Spring selbst verwendet (\url{https://start.spring.io/}). Zudem wird das Java SDK Version 17 verwendet. Für Apache Maven wird die Version 3.9.1 verwendet. Für die Authentifizierung wird das \verb|gloud| cli verwendet. Dieses wird über die offizielle Dokumentation installiert. Siehe \url{https://cloud.google.com/sdk/docs/install?hl=de}. Das AWS Toolkit wird für die Authentifizierung mit AWS angewendet. Um sich mit GC zu verbinden wird eine Methode des ADC verwendet, welches im nächsten Abschnitt genauer erläutert wird.

\newpage

\section{Speicherung von Binärdaten}

Um Daten in S3 oder Cloud Storage speichern zu können, wurde der Prototyp so implementiert, dass der Nutzer sich zwischen S3 oder Cloud Storage entscheiden kann. Dies geschieht über die Klasse \verb|CloudStorageServiceFactory|. Hier kann der Nutzer über die Umgebungsvariable \verb|cloud_provider| den gewünschten Provider mit \verb|aws| oder \verb|google cloud| angeben. Dabei wird die Groß-, und Kleinschreibung nicht berücksichtigt. Die Umgebungsvariablen können unter Linux, OSX und Unix im System durch \verb|export <EnvironmentVariable>=<value>| exportiert werden. Wenn eine IDE wie Intellij verwendet wird, kann dies unter den Run-Einstellungen als Umgebungsvariablen eingefügt werden. Nach der Eingabe des Cloud Providers wird das Programm die entsprechende Klasse aufrufen. Für AWS die Klasse \verb|AWSS3StorageService| und für GC die Klasse \verb|GCStorageService|. Beide Klassen implementieren das Interface \verb|CloudStorageService|. Dieses definiert zwei Methoden und eine davon ist für die Speicherung der Daten zuständig:

\begin{lstlisting}[language=Java]
void uploadObject(String bucketName, String key, String file, String encryptionKey, String storageClass) throws IOException;
\end{lstlisting}
	
Dieser Methode wird der Bucket Name, der Name des Objekts, der Pfad des Objekts und der Encryption Key übergeben. Der Encryption Key kann dabei der Schlüssel sein, der in AWS KMS oder GC KMS generiert wurde. Die Implementierung dieser Methode ist für beide Cloud Provider ähnlich gestaltet.

\begin{lstlisting}[language=Java, caption=Prototyp Code Snippet - Hochladen eines Objekts nach S3]
@Override
public void uploadObject(String bucketName, String key, String file, String encryptionKey, String storageClass) {
    try {

(1)     PutObjectRequest putObjectRequest = PutObjectRequest.builder()
(2)             .bucket(bucketName)
(3)             .key(key)
(4)             .serverSideEncryption(ServerSideEncryption.AWS_KMS)
(4)             .ssekmsKeyId(encryptionKey)
(5)             .storageClass(storageClass)
                .build();

(6)     Path filePath = Paths.get(file);
(7)     byte[] fileBytes = Files.readAllBytes(filePath);
(8)     RequestBody requestBody = RequestBody.fromBytes(fileBytes);

(9)     this.s3Client.putObject(putObjectRequest, requestBody);
        logger.info(
        "File " + file + " uploaded to bucket " + bucketName + " as " + key
        );

    } catch (S3Exception | IOException e) {
        logger.error(e.getMessage());
    }
}
\end{lstlisting}

\newpage

Der vorliegende Code (3.1) beschreibt den Vorgang des Speicherns eines Objekts in AWS S3. Zunächst wird ein PUT-Request-Objekt erstellt (1), wobei Parameter wie der Bucket-Name (2), der Objektname als Key (3) und die Authentifizierungsmethoden (4) angegeben werden. Dabei wird die AWS KMS-Methode verwendet und der entsprechende Schlüssel bereitgestellt (4). Anschließend wird die Speicherklasse angegeben, in der das Objekt gespeichert werden soll (5). In diesem Beispiel wird die Standard-IA-Klasse verwendet. Danach wird der Pfad der angegebenen Datei gelesen (6), in ein Byte-Array umgewandelt (7) und dem \verb|RequestBody| übergeben (8). Der RequestBody wird gemeinsam mit dem \verb|PutObjectRequest| an den \verb|S3Client| übergeben und mit der AWS \verb|.putObject()| Methode in S3 hochgeladen (9). AWS S3 verschlüsselt das Objekt mit dem angegebenen Schlüssel und lädt es in S3 hoch.\\

Das folgende Code Snippet zeigt die Methode der Klasse \verb|GCStorageService|. Ähnlich wie bei der Methode für AWS S3 wird auch hier ein Objekt nach Cloud Storage hochgeladen:

\begin{lstlisting}[language=Java, caption=Prototyp Code Snippet - Hochladen eines Objekts nach Cloud Storage]
@Override
public void uploadObject(String bucketName, String key, String file, String encryptionKey, String storageClass) throws IOException {

    Map<String, String> kmsKeyName = new HashMap<>();
    kmsKeyName.put("kmsKeyName", encryptionKey);

    // Get a reference to the bucket
(1) BlobId blobId = BlobId.of(bucketName, key);
(2) BlobInfo blobInfo = BlobInfo.newBuilder(blobId)
            .setMetadata(kmsKeyName)
            .build();

    Storage.BlobWriteOption precondition;
    if (this.storage.get(bucketName, key) == null) {
        precondition = Storage.BlobWriteOption.doesNotExist();
    } else {
        precondition =
                Storage.BlobWriteOption.generationMatch(
                        this.storage.get(bucketName, key).getGeneration());
    }
(3) this.storage.createFrom(blobInfo, Paths.get(file), precondition);

    logger.info(
    "File " + file + " uploaded to bucket " + bucketName + " as " + key
    );

}
\end{lstlisting}

Dabei werden ähnliche Parameter der Methode wie in AWS S3 übergeben. Um ein Objekt in einen Bucket hochladen zu können, wird eine Referenz zu diesem erstellt. Dies geschieht durch die \verb|BlobId|, welche den Bucket Namen und den Namen des Objekts beinhaltet (1). 
Anschließend wird diese blobId dem \verb|BlobInfo| Objekt übergeben und der Encryption Key über die Metadaten \verb|kmsKeyName| gesetzt (2). Nachdem überprüft worden ist, ob das Objekt bereits im Bucket existiert, wird das Objekt hochgeladen (3).\\

Um das Programm auszuführen, wird die Hauptklasse \verb|CloudGcStorageAwsS3Application| gestartet. Damit das Programm erfolgreich läuft, müssen die Umgebungsvariablen im System exportiert werden. Alle Umgebungsvariablen sind in der \verb|application.properties| hinterlegt. Diese werden beim Start des Programms gelesen und angewendet. Außerdem müssen die AWS und GC Credentials hinterlegt werden. Dies kann entweder über die AWS Toolkit Plugin gesteuert werden oder in der Kommandozeile mit dem Befehl \verb|aws configure|. Für GC Credentials kann mit dem Befehl:\\ \verb|export GOOGLE_APPLICATION_CREDENTIALS=<service-account-json-file>| der Service Account hinterlegt werden oder durch Ausführen des Befehls \verb|gcloud auth application-default login| in der Kommandozeile, was die Credentials lokal speichert und für ADC verwendet wird.

\newpage

\section{Bereitstellung der Binärdaten}

Bei der Bereitstellung von Binärdaten in leoticket geht es darum, den Kunden Dateien über Links zugänglich zu machen. Hierfür werden signierte URLs verwendet. Im folgenden Abschnitt werden die Implementierungen und Erläuterungen des entsprechenden Codes von beiden Cloud Providern vorgestellt.\\

Folgender Code Snippet (3.3) zeigt die Methode \verb|getPresignedUrl| zur Generierung einer signierten URL der Klasse \textbf{AWSS3StorageService}:

\begin{lstlisting}[language=Java, caption=Prototyp Code Snippet - Generierung einer signierten URL durch AWS]
@Override
public URL getPresignedUrl(String bucket, String key, Integer minutes, String encryptionKey) {
    try {

(1)     GetObjectRequest getObjectRequest = 
			GetObjectRequest.builder()
(2)             .bucket(bucket)
(3)             .key(key)
                .build();

        GetObjectPresignRequest getObjectPresignRequest =                  
             GetObjectPresignRequest.builder()
(4)             .getObjectRequest(getObjectRequest)
(5)             .signatureDuration(Duration.ofMinutes(minutes))
                .build();

        PresignedGetObjectRequest presignedGetObjectRequest =                  
(6)          presigner.presignGetObject(getObjectPresignRequest);

(7)     URL url = presignedGetObjectRequest.url();

        logger.info("Presigned URL: " + url);

        return url;

    } catch (S3Exception e) {
        logger.error(e.getMessage());
    }

    return null;
}
\end{lstlisting}

Die Methode erhält ähnlich wie beim Hochladen des Objekts die Parameter Bucket-Name und Objektname. Zudem wird eine Zeitdauer in Minuten übergeben, die festlegt, wie lange der generierte Link gültig sein soll. Für die Entschlüsselung der Daten muss der gleiche Encryption Key wie beim Hochladen verwendet werden. Das \verb|GetObjectRequest| Objekt wird erstellt (1) und mit dem Bucket-Namen (2) und dem Objektnamen (3) versehen. Anschließend wird dieses Objekt an das \verb|GetObjectPresignRequest| Objekt übergeben (4) und die Gültigkeitsdauer der Signatur angegeben (5). Die Gültigkeitsdauer bestimmt, wie lange die signierte URL valide ist. Um die signierte URL zu generieren, wird das \verb|GetObjectPresignRequest| Objekt an den \verb|S3Presigner| übergeben (6), auf welche die Methode \verb|presignGetObject()| aufgerufen wird (6). 

Das generierte \verb|PresignedGetObjectRequest| wird als URL gespeichert (7) und ausgegeben.\\

Folgende Abbildung zeigt die Methode zur Generierung einer signierten URL der \\Klasse \verb|GCStorageService|:

\begin{lstlisting}[language=Java, caption=Prototyp Code Snippet - Generierung einer signierten URL durch GC]
@Override
public URL getPresignedUrl(String bucketName, String key, Integer minutes, String encryptionKey) {
    try {
        Map<String, String> kmsKeyName = new HashMap<>();
        kmsKeyName.put("kmsKeyName", encryptionKey);

        // Define resource
(1)     BlobInfo blobInfo = BlobInfo.newBuilder(BlobId.of(bucketName, key))
                .setMetadata(kmsKeyName)
                .build();

(2)     URL url = this.storage.signUrl(
(3)             blobInfo,
(4)             minutes,
                TimeUnit.MINUTES,
(5)             Storage.SignUrlOption.withV4Signature()
        );

        logger.info("Generated GET signed URL: " + url);

(6)     return url;

    } catch (StorageException e) {
        logger.error(e.getMessage());
    }

    return null;
}
\end{lstlisting}

Ähnlich wie bei S3 wird eine Referenz zum Objekt erstellt, indem der Bucket Name und der Name des Objekts dem \verb|BlobInfo| Objekt mitgegeben wird (1). Anschließend kann die URL durch Aufrufen der Methode \verb|.signUrl()| erstellt werden (2). Hier werden die \verb|BlobInfo| Objekt (3), die Minuten (4) und die Signatur Methode (5) übergeben. Zuletzt wird die URL ausgegeben (6).\\

Mit signierten URLs können die Anforderungen von leoticket an die sichere Speicherung und Bereitstellung der Daten über signierte URLs berücksichtigt werden. Dies bedeutet, Kunden können über diese Links die Dateien für Tickets und Rechnungen herunterladen ohne das Problem von zu großen Email-Anhängen zu haben.\\

\newpage

\section{Messung der Performance}

In diesem Abschnitt erfolgt die Messung der Performance für die Dienste von AWS und GC. Dabei werden bis zu 1000 generierte Dateien sowohl für den Upload als auch für den Download betrachtet. Die Performance Analyse wird auf einer virtuellen Maschine in der Hetzner Cloud ausgeführt, um eine isolierte Umgebung zu gewährleisten. Die Performance-Messung beim Hoch- und Herunterladen kann jedoch von verschiedenen Faktoren wie Netzwerklatenz, verfügbarer Bandbreite, Serverkapazität, Datenmenge und der Auslastung der Server beeinflusst werden. Außerdem kann der Hetzner Server näher an AWS oder GC liegen und dies könnte dazu führen, dass die Dauer des Hoch-, und Herunterladens aus diesem Grund kürzer ist. Die Messungen dienen lediglich dem groben Vergleich beider Cloud Provider. Die Performance-Messung wird auf verschiedene Speicherklassen durchgeführt, um einen Vergleich zwischen diesen zu ermöglichen und eine Grundlage für die Bewertung ihrer Leistungsfähigkeit zu schaffen.\\

\textbf{AWS}\\

AWS bietet Dienste für die Performance Analyse. Unter anderem die Amazon CloudWatch, S3 Storage Lens und die S3 Transfer Acceleration. Die AWS CLI stellt einfache Methoden zum S3 Upload und Download Tests vor. Beispielsweise kann man mit dem Befehl:

\begin{lstlisting}
	aws s3 cp <lokaler_pfad> s3://<Bucket_Name>/<Ziel_Dateipfad>
\end{lstlisting}

Dateien hoch,-und herunterladen und die Zeit für die benötigte Request messen. Auch mit dem AWS SDK können Performance Test Skripte geschrieben werden. Diese Methode wird für den Prototypen angewendet. Dabei werden Tests bereitgestellt, die mehrere Dateien automatisch hoch-, und herunterladen und dabei die vergangene Zeit messen.\\ 

\textbf{GC Storage}\\

GC bietet ein eigenes \verb|gsutil| Tool für die Performance Analyse. Wie im Abschnitt Performance bereits erwähnt, können durch die \verb|perfdiag| Funktion Performance Diagnosen erstellt werden.\\ 

Mehrere Testdateien werden aus einem angegebenen Bucket hoch-, und heruntergeladen. Nach der Analyse werden alle Testdateien nach erfolgreicher Diagnose gelöscht. Die \verb|gsutil| Performance kann von einigen Faktoren wie vom Client, Server oder Netzwerk beeinflusst werden. Möglich sind die Leistung, der verfügbare Speicher, die Netzwerk Bandbreite, Firewalls und Fehlerraten zwischen \verb|gsutil| und den Google Servern. Die \verb|perfiag| Funktion wurde bereitgestellt, damit Nutzer Messungen durchführen können, die beim Troubleshooting von Performance Problemen helfen, vgl. \cite{gc-perfdiag}.\\

Um die Performance Diagnose auszuführen, kann der folgende Befehl verwendet werden:

\begin{lstlisting}
	gsutil perfdiag -o test.json -n 67000 -s 400kb gs://leoticket-bucket
\end{lstlisting}

Die \verb|-o| Option schreibt den Output des Ergebnisses in eine Datei. Die Output Datei ist eine JSON Datei mit System Informationen und enthält die Performance Diagnose Ergebnisse. Die -n Option setzt die Anzahl der Objekte, die heruntergeladen und hochgeladen werden sollen während des Tests. Mit der \verb|-s| Option kann man die Objektgröße angeben. Zum Schluss wird der Name des Buckets angegeben.\\

Um die Performance der SDKs zu analysieren, werden Objekte mit jeweils 100kb Objektgröße in verschiedenen Speicherklassen hoch-, und heruntergeladen. Anschließend wird die Performance über das SDK von Cloud Storage ähnlich wie bei AWS getestet. Der Test wird ebenfalls auf einer virtuellen Maschine von Hetzner ausgeführt.\\

Die Performance wird in Zehner-Vielfachen gemessen, beginnend mit einer Datei bis hin zu 1000 Dateien. Dies bedeutet, dass Messungen für eine Datei, zehn Dateien, 100 Dateien und 1000 Dateien durchgeführt werden. Zur Durchführung der Messung wird eine Java Jar-Datei des Prototyps erstellt, in der die Testmethoden ausgeführt werden. Diese Testmethoden generieren zunächst Testdaten, die mit zufälligen String-Werten der Größe 100 KB gefüllt sind. Anschließend werden die Testmethoden in der Kommandozeile ausgeführt.

\newpage

\subsection{Messungsergebnisse}

In diesem Abschnitt werden die Messungsergebnisse der Performance Messung in Millisekunden präsentiert. Die Speicherklassen Standard, Standard-IA und One Zone-IA von AWS wurden jeweils mit Standard, Nearline und Coldline von GC verglichen. Im Folgenden werden die Ergebnisse der Upload und Download Dauer aller Speicherklassen präsentiert: 

\begin{table}[!h]
\centering
\begin{tabular}{ |s|p{3cm}|p{3cm}| }
\hline
\rowcolor{pink!35}
 & \textbf{Standard-IA} & \textbf{Nearline}\\
\hline
\textbf{1 Datei} &  &  \\
Upload & 705 & 841 \\
Download   &  18 & 26 \\
\textbf{10 Dateien}  & &  \\
Upload & 1862 & 3217\\
Download   &  35 & 94 \\
\textbf{100 Dateien}  & &  \\
Upload & 16681 & 22683\\
Download   &  129 & 269 \\
\textbf{1000 Dateien}  & & \\
Upload & 71175 & 185134\\
Download   &  663 & 1489 \\
\hline
\end{tabular}
\caption{Ergebnisse der Upload und Download Dauer der Speicherklassen Standard-IA und Nearline}
\end{table}


\begin{table}[!h]
\centering
\begin{tabular}{ |s|p{3cm}|p{3cm}| }
\hline
\rowcolor{pink!35}
 & \textbf{Standard S3} & \textbf{Standard GCS}\\
\hline
\textbf{1 Datei} &  &  \\
Upload & 585 & 660 \\
Download   &  28 & 19 \\
\textbf{10 Dateien}  & &  \\
Upload & 1369 & 3002\\
Download   &  70 & 108 \\
\textbf{100 Dateien}  & &  \\
Upload & 8110 & 20750\\
Download   &  180 & 396 \\
\textbf{1000 Dateien}  & & \\
Upload & 73992 & 176004\\
Download   &  650 & 1619 \\
\hline
\end{tabular}
\caption{Ergebnisse der Upload und Download Dauer der Speicherklassen Standard S3 und Standard GCS}
\end{table}

\newpage

\begin{table}[!h]
\centering
\begin{tabular}{ |s|p{3cm}|p{3cm}| }
\hline
\rowcolor{pink!35}
 & \textbf{OneZone-IA} & \textbf{Coldline}\\
\hline
\textbf{1 Datei} &  &  \\
Upload & 505 & 636 \\
Download   &  28 & 18 \\
\textbf{10 Dateien}  & &  \\
Upload & 1105 & 2855\\
Download   &  65 & 89 \\
\textbf{100 Dateien}  & &  \\
Upload & 7539 & 20391\\
Download   &  187 & 250 \\
\textbf{1000 Dateien}  & & \\
Upload & 73086 & 163661\\
Download   &  701 & 1559 \\
\hline
\end{tabular}
\caption{Ergebnisse der Upload und Download Dauer der Speicherklassen OneZone-IA und Coldline}
\end{table}

Die Ergebnisse werden im Kapitel Zusammenfassung der Ergebnisse untersucht und dargestellt.

\newpage

\section{Zusammenfassung der Implementierung}

Der Prototyp soll einen Vergleich zwischen den beiden Cloud Providern bieten. Das Ziel dabei ist es, ähnliche Technologien von beiden Providern zu verwenden und die Performance mit Testdaten messen zu können. 

Der Prototyp implementiert zwei wichtige Funktionen: Das Hochladen und Herunterladen von Dateien unter Berücksichtigung der Anforderungen von leoticket. Dabei werden signierte URLs zur Bereitstellung der Dateien verwendet und die SSE KMS von beiden Providern für die Datenverschlüsselung angewendet. Der Prototyp soll auch als externe Bibliothek für eigene Anwendungen integriert werden können. Bei der Implementierung wurden die offiziellen Dokumentationen von AWS und Google Cloud verwendet, um die aktuellsten Versionen zum Zeitpunkt der Arbeit zu verwenden. Auf Wunsch von Leomedia wurde Spring Boot als Framework gewählt, um eine Enterprise-Anwendung bereitzustellen. Java wurde aus Präferenzgründen als Programmiersprache gewählt, obwohl beide Provider viele weitere Sprachen, die bereits im Kapitel zur API-Anbindung erwähnt wurden, unterstützen.\\

Der Prototyp umfasst eine Implementierung, die es ermöglicht, über eine Umgebungsvariable zwischen AWS und GC zu wählen. Die Klasse \verb|CloudStorageServiceFactory| stellt die Auswahl zwischen AWS und GC zur Verfügung. Je nachdem welchen Cloud Provider der Nutzer angegeben hat, wird die entsprechende Klasse instanziert und aufgerufen. Die Klassen \verb|AWSS3StorageService| und \verb|GCStorageService| implementieren die Methoden des Interfaces \verb|CloudStorageService|.\\

Die bereitgestellten Tests dienen der Performance Messung. Dabei werden Dateien automatisch als 100kb große Objekte erstellt und durch die Testmethoden verwendet, um Objekte hoch-, und herunterzuladen. Sie unterstützen dabei, die Dauer der verschiedenen Funktionen zu messen.\\

Da die Maven Abhängigkeiten kein Teil der Spring Cloud Release Train sind, hängt es von der Community ab, die Versionen aktuell zu halten. Für AWS bedeutet dies, dass die AWS SDK 2.0 Version nicht komplett abgedeckt ist. Jedoch ist sie so weit, dass S3 bereits unterstützt wird. 